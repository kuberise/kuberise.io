{{- if .Values.enable_ollama }}
# This template will only be rendered when enable_openai is set to true
apiVersion: core.k8sgpt.ai/v1alpha1
kind: K8sGPT
metadata:
  name: k8sgpt-ollama
spec:
  ai:
    enabled: true
    backend: localai
    model: llama3.2
    baseUrl: http://ollama.ollama.svc.cluster.local:11434/
    # backOff:
    #   # Enable backOff to implement rate limiting and avoid quota issues
    #   enabled: true
    #   # Increase maxRetries to give more attempts with exponential backoff
    #   maxRetries: 30
  repository: ghcr.io/k8sgpt-ai/k8sgpt
  version: v0.4.1
  # Set a schedule for analysis instead of continuous analysis
  filters:
    # Add specific filters to limit resources being analyzed
    - Deployment
    - StatefulSet
    - Pod
    - Secret
    - Ingress
  # Enable caching to reduce API calls
  noCache: false
{{- end }}
